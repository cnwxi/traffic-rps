{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要的依赖包\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "# 升腾环境\n",
    "# import torch_npu \n",
    "# from torch_npu.contrib import transfer_to_npu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义显示图像函数\n",
    "def display_image(data_dir):\n",
    "\tx_dir=[]\n",
    "\tx_filename=[]\n",
    "\tx_len=0\n",
    "\t#显示数据集大小\n",
    "\tfor i in range(5):\n",
    "\t\tx_dir.append(os.path.join(data_dir,str(i)))\n",
    "\t\tx_filename.append(os.listdir(x_dir[i]))\n",
    "\t\tx_len=x_len+len(x_filename[i])\n",
    "\tprint(\"数据集大小为：\",x_len)\n",
    "\t#随机抽取图像存入image列表\n",
    "\timage=[]\n",
    "\tfor i in range(5):\n",
    "\t\tfor j in range(2):\n",
    "\t\t\tt=np.random.randint(0,len(x_filename[i]))\n",
    "\t\t\timage.append(x_dir[i]+'/'+x_filename[i][t])\n",
    "\t#显示image列表中的图像\n",
    "\ti=1\n",
    "\tfor img_path in image:\n",
    "\t\tplt.subplot(2, 5, i)\n",
    "\t\timg=mpimg.imread(img_path)\n",
    "\t\tplt.imshow(img)\n",
    "\t\tplt.axis('Off')\n",
    "\t\ti=i+1\n",
    "\tplt.show()\n",
    "display_image(\"./traffic/train/\")\n",
    "display_image(\"./traffic/validation/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对训练集做数据归一化及增强处理\n",
    "TRAINING_DIR=\"./traffic/train/\"\n",
    "\n",
    "# 定义图像预处理和增强\n",
    "def remove_alpha_channel(image):\n",
    "    if image.mode == 'RGBA':\n",
    "        return image.convert('RGB')\n",
    "    else:\n",
    "        return image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((150, 150)),  # 调整图像大小\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomRotation(40),  # 随机旋转\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=0.2, scale=(0.8, 1.2)),  # 随机仿射变换，包括平移、剪切、缩放\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1./255, 1./255, 1./255], [1, 1, 1])  # 对每个通道进行归一化，均值为1/255，标准差为1\n",
    "])\n",
    "\n",
    "# 使用ImageFolder加载数据\n",
    "TRAINING_DIR = \"./traffic/train/\"\n",
    "train_dataset = datasets.ImageFolder(TRAINING_DIR, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#对验证集做数据归一化处理\n",
    "VALIDATION_DIR=\"./traffic/validation/\"\n",
    "# 定义验证集的图像预处理\n",
    "validation_transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((150, 150)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1./255, 1./255, 1./255], [1, 1, 1])  # 对每个通道进行归一化\n",
    "])\n",
    "\n",
    "# 使用ImageFolder加载验证集数据\n",
    "VALIDATION_DIR = \"./traffic/validation/\"\n",
    "validation_dataset = datasets.ImageFolder(VALIDATION_DIR, transform=validation_transform)\n",
    "\n",
    "# 创建验证集的数据加载器\n",
    "validation_loader = DataLoader(validation_dataset,\n",
    "                               batch_size=32,\n",
    "                               shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看训练集的标签\n",
    "print(train_dataset.class_to_idx)\n",
    "\n",
    "# 查看验证集的标签\n",
    "print(validation_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TrafficSignNet, self).__init__()\n",
    "        # 第一组“卷积层+池化层+Dropout层” 输入 3*150*150\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)  # 64*148*148\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64*74*74\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        # 第二组“卷积层+池化层+Dropout层”\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)  # 64*72*72\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64*36*36\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        # 第三组“卷积层+池化层+Dropout层”\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)  # 128*34*34\n",
    "        self.activation3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128*17*17\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        # 第四组“卷积层+池化层+Dropout层”\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)  # 128*15*15\n",
    "        self.activation4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128*7*7\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        # 拉伸层和Dropout层\n",
    "        self.flatten = nn.Flatten()  # 128*7*7=6272\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        # 全连接层和Dropout层\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512) # 输出512维特征\n",
    "        self.dropout6 = nn.Dropout(0.5)\n",
    "        # 输出层\n",
    "        self.fc2 = nn.Linear(512, 5) # 输出5个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.pool1(self.activation1(self.conv1(x))))\n",
    "        x = self.dropout2(self.pool2(self.activation2(self.conv2(x))))\n",
    "        x = self.dropout3(self.pool3(self.activation3(self.conv3(x))))\n",
    "        x = self.dropout4(self.pool4(self.activation4(self.conv4(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout6(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1) # 使用softmax函数将输出转换为概率\n",
    "        return x\n",
    "\n",
    "# 创建模型实例并打印模型概要\n",
    "model = TrafficSignNet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA是否可用，据此设置设备\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): # 英伟达GPU\n",
    "    print(\"Using GPU for training\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): # Apple M芯片\n",
    "        print(\"Using NPU for training\")\n",
    "        device = torch.device(\"mps\")\n",
    "else: # CPU\n",
    "    print(\"Using CPU for training\")\n",
    "    device = torch.device(\"cpu\")\n",
    "model = model.to(device)  # 将模型移动到指定的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 创建保存模型权重的文件夹\n",
    "if not os.path.exists(\"./weight\"):\n",
    "    os.makedirs(\"./weight\")\n",
    "\n",
    "# 训练网络模型\n",
    "def train_model(model, train_loader, validation_loader, epochs):\n",
    "    writer = SummaryWriter('./runs/traffic_log')  # 初始化SummaryWriter\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        with tqdm(total=len(train_loader),\n",
    "                  ncols=150,\n",
    "                  desc=f\"epoch:{epoch+1}/{epochs}\") as pBar:\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                pBar.update()\n",
    "                pBar.set_description(\n",
    "                    f\"epoch:{epoch+1}/{epochs}|running_loss:{loss.item()/len(inputs)}\"\n",
    "                )\n",
    "            epoch_loss = running_loss / len(train_loader)/32\n",
    "            pBar.set_description(\n",
    "                f\"epoch:{epoch+1}/{epochs}|epch_loss:{epoch_loss}\")\n",
    "        writer.add_scalar('Loss/Training', epoch_loss, epoch)  # 记录训练损失\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        acc = 0.0\n",
    "        best_acc = 0.0\n",
    "        with torch.no_grad(), tqdm(total=len(validation_loader),\n",
    "                                   ncols=150,\n",
    "                                   desc=f\"validate:{epoch}/{epochs}\") as pBar:\n",
    "            for inputs, labels in validation_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                pBar.update()\n",
    "            acc = 100 * correct / total\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model.state_dict(), \"./weight/best_traffic.pth\")\n",
    "            pBar.set_description(f\"validate:{epoch+1}/{epochs}|acc:{acc:.2f}\")\n",
    "        writer.add_scalar('Validation Accuracy', acc, epoch)  # 记录验证准确率\n",
    "\n",
    "# 假设 train_loader 和 validation_loader 已经定义\n",
    "train_model(model, train_loader, validation_loader, epochs=10)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"./weight/traffic.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = TrafficSignNet()\n",
    "model.load_state_dict(torch.load(\"./weight/best_traffic.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "# 读取测试集\n",
    "TEST_DIR = \"./traffic/test/\"\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((150, 150)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1. / 255, 1. / 255, 1. / 255],\n",
    "                         [1, 1, 1])  # 对每个通道进行归一化\n",
    "])\n",
    "# 对单张图像进行预测\n",
    "def predict_image(model, image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = test_transform(image).to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "\n",
    "label_map = {0: \"120\", 1: \"no\", 2: \"80\", 3: \"direct\", 4: \"100\"}\n",
    "with torch.no_grad():\n",
    "    for i in range(10): \n",
    "        plt.subplot(2, 5, i+1)\n",
    "        image_path = f\"./traffic/test/{i+1}.png\"\n",
    "        img=mpimg.imread(image_path)\n",
    "        plt.title(label_map[predict_image(model, image_path)])\n",
    "        plt.imshow(img)\n",
    "        plt.axis('Off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
