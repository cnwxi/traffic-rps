{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import math\n",
    "# 升腾环境\n",
    "# import torch_npu \n",
    "# from torch_npu.contrib import transfer_to_npu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对训练集做数据归一化及增强处理\n",
    "TRAINING_DIR=\"./rps/train/\"\n",
    "# 定义图像预处理和增强\n",
    "def remove_alpha_channel(image):\n",
    "    if image.mode == 'RGBA':\n",
    "        return image.convert('RGB')\n",
    "    else:\n",
    "        return image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((256, 256)),  # 调整图像大小\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomRotation(40),  # 随机旋转\n",
    "    transforms.RandomAffine(degrees=0,\n",
    "                            translate=(0.2, 0.2),\n",
    "                            shear=0.2,\n",
    "                            scale=(0.8, 1.2)),  # 随机仿射变换，包括平移、剪切、缩放\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1. / 255, 1. / 255, 1. / 255],\n",
    "                         [1, 1, 1])  # 对每个通道进行归一化，均值为1/255，标准差为1\n",
    "])\n",
    "TRAINING_DIR=\"./rps/train/\"\n",
    "train_dataset = datasets.ImageFolder(TRAINING_DIR, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#对验证集做数据归一化处理\n",
    "VALIDATION_DIR=\"./rps/val/\"\n",
    "# 定义验证集的图像预处理\n",
    "validation_transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((256, 256)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1. / 255, 1. / 255, 1. / 255],\n",
    "                         [1, 1, 1])  # 对每个通道进行归一化\n",
    "])\n",
    "VALIDATION_DIR=\"./rps/val/\"\n",
    "validation_dataset = datasets.ImageFolder(VALIDATION_DIR, transform=validation_transform)\n",
    "\n",
    "# 创建验证集的数据加载器\n",
    "validation_loader = DataLoader(validation_dataset,\n",
    "                               batch_size=32,\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels, patch_size, embed_dim, num_patches, dropout):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=embed_dim, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.Flatten(2)\n",
    "        )\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(size=(1, 1, embed_dim)), requires_grad=True)\n",
    "        self.position_embedding = nn.Parameter(torch.randn(size=(1, num_patches+1, embed_dim)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "\n",
    "        x = self.patcher(x).permute(0, 2, 1)\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        x = x + self.position_embedding\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RPSTrans(nn.Module):\n",
    "    def __init__(self, in_channels, patch_size, embed_dim, num_patches, dropout,\n",
    "                 num_heads, activation, num_encoders, num_classes):\n",
    "        super(RPSTrans, self).__init__()\n",
    "        self.patch_embedding = PatchEmbedding(in_channels, patch_size, embed_dim, num_patches, dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout,\n",
    "                                                   activation=activation,\n",
    "                                                   batch_first=True, norm_first=True)\n",
    "        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim),\n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.MLP(x[:, 0, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "IN_CHANNELS = 3\n",
    "PATCH_SIZE = 16\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2 \n",
    "EMBED_DIM = (PATCH_SIZE ** 2) * IN_CHANNELS  \n",
    "DROPOUT = 0.001\n",
    "\n",
    "NUM_HEADS = 8\n",
    "ACTIVATION = \"gelu\"\n",
    "NUM_ENCODERS = 4\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RPSTrans(IN_CHANNELS, PATCH_SIZE, EMBED_DIM, NUM_PATCHES, DROPOUT, NUM_HEADS, ACTIVATION, NUM_ENCODERS,\n",
    "            NUM_CLASSES).to(device)\n",
    "x = torch.randn(size=(1, 3, 256, 256)).to(device)\n",
    "prediction = model(x)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA是否可用，据此设置设备\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available(): # 英伟达GPU\n",
    "    print(\"Using GPU for training\")\n",
    "    devvice = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available(): # Apple M芯片\n",
    "        print(\"Using NPU for training\")\n",
    "        device = torch.device(\"mps\")\n",
    "else: # CPU\n",
    "    print(\"Using CPU for training\")\n",
    "    device = torch.device(\"cpu\")\n",
    "model = model.to(device)  # 将模型移动到指定的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),  lr=1e-4)\n",
    "\n",
    "# 创建保存模型权重的文件夹\n",
    "if not os.path.exists(\"./weight\"):\n",
    "    os.makedirs(\"./weight\")\n",
    "    \n",
    "# 训练网络模型\n",
    "def train_model(model, train_loader, validation_loader, epochs):\n",
    "    writer = SummaryWriter('./runs/rps_trans_log')  # 初始化SummaryWriter\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        with tqdm(total=len(train_loader),\n",
    "                  ncols=150,\n",
    "                  desc=f\"epoch:{epoch+1}/{epochs}\") as pBar:\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                pBar.update()\n",
    "                pBar.set_description(\n",
    "                    f\"epoch:{epoch+1}/{epochs}|running_loss:{loss.item()/len(inputs)}\"\n",
    "                )\n",
    "            epoch_loss = running_loss / len(train_loader) / 32\n",
    "            pBar.set_description(\n",
    "                f\"epoch:{epoch+1}/{epochs}|epch_loss:{epoch_loss}\")\n",
    "        writer.add_scalar('Loss/Training', epoch_loss, epoch)  # 记录训练损失\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        acc = 0.0\n",
    "        best_acc = 0.0\n",
    "        with torch.no_grad(), tqdm(total=len(validation_loader),\n",
    "                                   ncols=150,\n",
    "                                   desc=f\"validate:{epoch+1}/{epochs}\") as pBar:\n",
    "            for inputs, labels in validation_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                pBar.update()\n",
    "            acc = 100 * correct / total\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model.state_dict(), \"./weight/best_rpsTrans.pth\")\n",
    "            pBar.set_description(f\"validate:{epoch+1}/{epochs}|acc:{acc:.2f}\")\n",
    "        writer.add_scalar('Validation Accuracy', acc, epoch)  # 记录验证准确率\n",
    "\n",
    "# 假设 train_loader 和 validation_loader 已经定义\n",
    "train_model(model, train_loader, validation_loader, epochs=10)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"./weight/rpsTrans.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./weight/best_rpsTrans.pth\"))\n",
    "total = 0\n",
    "correct = 0\n",
    "acc = 0.0\n",
    "best_acc = 0.0\n",
    "with torch.no_grad(), tqdm(total=len(train_loader),\n",
    "                            ncols=150,\n",
    "                            desc=f\"validate:\") as pBar:\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        pBar.update()\n",
    "    acc = 100 * correct / total\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    pBar.set_description(f\"validate:|acc:{acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "IN_CHANNELS = 3\n",
    "PATCH_SIZE = 16\n",
    "NUM_PATCHES = (IMG_SIZE // PATCH_SIZE) ** 2 \n",
    "EMBED_DIM = (PATCH_SIZE ** 2) * IN_CHANNELS  \n",
    "DROPOUT = 0.001\n",
    "\n",
    "NUM_HEADS = 8\n",
    "ACTIVATION = \"gelu\"\n",
    "NUM_ENCODERS = 4\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = RPSTrans(IN_CHANNELS, PATCH_SIZE, EMBED_DIM, NUM_PATCHES, DROPOUT, NUM_HEADS, ACTIVATION, NUM_ENCODERS,\n",
    "            NUM_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(\"./weight/best_rpsTrans.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((256, 256)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1. / 255, 1. / 255, 1. / 255],\n",
    "                         [1, 1, 1])  # 对每个通道进行归一化\n",
    "])\n",
    "# 对单张图像进行预测\n",
    "def predict_image(model, image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = test_transform(image).to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "\n",
    "label_map = {0: \"paper\", 1: \"rock\", 2: \"scissors\"}\n",
    "with torch.no_grad():\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        image_path = f\"./rps/test/{i+1}.png\"\n",
    "        img=mpimg.imread(f\"./rps/test/{i+1}.png\")\n",
    "        plt.imshow(img)\n",
    "        plt.title(label_map[predict_image(model, image_path)])\n",
    "        plt.axis('Off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
