{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter  # 导入SummaryWriter\n",
    "from PIL import Image\n",
    "# 升腾环境\n",
    "# import torch_npu \n",
    "# from torch_npu.contrib import transfer_to_npu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像显示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义显示图像函数\n",
    "def display_image(data_dir):\n",
    "    x_dir = []\n",
    "    x_filename = []\n",
    "    x_len = 0\n",
    "    #显示数据集大小\n",
    "    for i in ['paper', 'rock', 'scissors']:\n",
    "        tmp_dir = os.path.join(data_dir, i)\n",
    "        x_dir.append(tmp_dir)\n",
    "        x_filename.append(os.listdir(tmp_dir))\n",
    "        x_len = x_len + len(os.listdir(tmp_dir))\n",
    "    print(\"数据集大小为：\", x_len)\n",
    "    #随机抽取图像存入image列表\n",
    "    image = []\n",
    "    for i in range(3):\n",
    "        for j in range(2):\n",
    "            t = np.random.randint(0, len(x_filename[i]))\n",
    "            image.append(x_dir[i] + '/' + x_filename[i][t])\n",
    "    #显示image列表中的图像\n",
    "    i = 1\n",
    "    for img_path in image:\n",
    "        plt.subplot(2, 3, i)\n",
    "        img = mpimg.imread(img_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('Off')\n",
    "        i = i + 1\n",
    "    plt.show()\n",
    "display_image(\"./rps/train\")\n",
    "display_image(\"./rps/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#对训练集做数据归一化及增强处理\n",
    "TRAINING_DIR=\"./rps/train/\"\n",
    "# 定义图像预处理和增强\n",
    "def remove_alpha_channel(image):\n",
    "    if image.mode == 'RGBA':\n",
    "        return image.convert('RGB')\n",
    "    else:\n",
    "        return image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((150, 150)),  # 调整图像大小\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomRotation(40),  # 随机旋转\n",
    "    transforms.RandomAffine(degrees=0,\n",
    "                            translate=(0.2, 0.2),\n",
    "                            shear=0.2,\n",
    "                            scale=(0.8, 1.2)),  # 随机仿射变换，包括平移、剪切、缩放\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1. / 255, 1. / 255, 1. / 255],\n",
    "                         [1, 1, 1])  # 对每个通道进行归一化，均值为1/255，标准差为1\n",
    "])\n",
    "TRAINING_DIR=\"./rps/train/\"\n",
    "train_dataset = datasets.ImageFolder(TRAINING_DIR, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#对验证集做数据归一化处理\n",
    "VALIDATION_DIR=\"./rps/val/\"\n",
    "# 定义验证集的图像预处理\n",
    "validation_transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((150, 150)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1. / 255, 1. / 255, 1. / 255],\n",
    "                         [1, 1, 1])  # 对每个通道进行归一化\n",
    "])\n",
    "VALIDATION_DIR=\"./rps/val/\"\n",
    "validation_dataset = datasets.ImageFolder(VALIDATION_DIR, transform=validation_transform)\n",
    "\n",
    "# 创建验证集的数据加载器\n",
    "validation_loader = DataLoader(validation_dataset,\n",
    "                               batch_size=32,\n",
    "                               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看训练集的标签\n",
    "print(train_dataset.class_to_idx)\n",
    "\n",
    "# 查看验证集的标签\n",
    "print(validation_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPSNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RPSNet, self).__init__()\n",
    "        # 第一组“卷积层+池化层+Dropout层” 输入尺寸 3*150*150\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)  # 64*148*148\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64*74*74\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        # 第二组“卷积层+池化层+Dropout层”\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3)  # 64*72*72\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64*36*36\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        # 第三组“卷积层+池化层+Dropout层”\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)  # 128*34*34\n",
    "        self.activation3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128*17*17\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        # 第四组“卷积层+池化层+Dropout层”\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)  # 128*15*15\n",
    "        self.activation4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128*7*7\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        # 拉伸层和Dropout层\n",
    "        self.flatten = nn.Flatten()  # 128*7*7=6272\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        # 全连接层和Dropout层\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
    "        self.dropout6 = nn.Dropout(0.5)\n",
    "        # 输出层\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.pool1(self.activation1(self.conv1(x))))\n",
    "        x = self.dropout2(self.pool2(self.activation2(self.conv2(x))))\n",
    "        x = self.dropout3(self.pool3(self.activation3(self.conv3(x))))\n",
    "        x = self.dropout4(self.pool4(self.activation4(self.conv4(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout6(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "# 创建模型实例并打印模型概要\n",
    "model = RPSNet()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA是否可用，据此设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)  # 将模型移动到指定的设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 训练网络模型\n",
    "def train_model(model, train_loader, validation_loader, epochs):\n",
    "    writer = SummaryWriter('./runs/rps_log')  # 初始化SummaryWriter\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        with tqdm(total=len(train_loader),\n",
    "                  ncols=150,\n",
    "                  desc=f\"epoch:{epoch+1}/{epochs}\") as pBar:\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                pBar.update()\n",
    "                pBar.set_description(\n",
    "                    f\"epoch:{epoch+1}/{epochs}|running_loss:{loss.item()/len(inputs)}\"\n",
    "                )\n",
    "            epoch_loss = running_loss / len(train_loader)/32\n",
    "            pBar.set_description(\n",
    "                f\"epoch:{epoch+1}/{epochs}|epch_loss:{epoch_loss}\")\n",
    "        writer.add_scalar('Loss/Training', epoch_loss, epoch)  # 记录训练损失\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        acc = 0.0\n",
    "        best_acc = 0.0\n",
    "        with torch.no_grad(), tqdm(total=len(validation_loader),\n",
    "                                   ncols=150,\n",
    "                                   desc=f\"validate:{epoch}/{epochs}\") as pBar:\n",
    "            for inputs, labels in validation_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                pBar.update()\n",
    "            acc = 100 * correct / total\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model.state_dict(), \"./weight/best_rps.pth\")\n",
    "            pBar.set_description(f\"validate:{epoch+1}/{epochs}|acc:{acc:.2f}\")\n",
    "        writer.add_scalar('Validation Accuracy', acc, epoch)  # 记录验证准确率\n",
    "\n",
    "# 假设 train_loader 和 validation_loader 已经定义\n",
    "train_model(model, train_loader, validation_loader, epochs=10)\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"./weight/rps.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载模型\n",
    "model = RPSNet()\n",
    "model.load_state_dict(torch.load(\"./weight/best_rps.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_alpha_channel), # 去除Alpha通道\n",
    "    transforms.Resize((150, 150)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize([1. / 255, 1. / 255, 1. / 255],\n",
    "                         [1, 1, 1])  # 对每个通道进行归一化\n",
    "])\n",
    "# 对单张图像进行预测\n",
    "def predict_image(model, image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = test_transform(image).to(device)\n",
    "    image = image.unsqueeze(0)\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "\n",
    "label_map = {0: \"paper\", 1: \"rock\", 2: \"scissors\"}\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    image_path = f\"./rps/test/{i+1}.png\"\n",
    "    img=mpimg.imread(f\"./rps/test/{i+1}.png\")\n",
    "    plt.imshow(img)\n",
    "    plt.title(label_map[predict_image(model, image_path)])\n",
    "    plt.axis('Off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
